{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/2834747658.py:19: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "from environment import SM_env\n",
    "from environment import random_normal_trunc\n",
    "from environment import eth_env\n",
    "from environment import SM_env_with_stale\n",
    "from environment import random_normal_trunc\n",
    "import mdptoolbox\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space size =  733\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/3431180317.py:120: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/3431180317.py:10: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/3431180317.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b26ab110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/3431180317.py:62: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b19a8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b19a8390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b19a8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b19a8390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b189ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b189ba50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b189ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64b189ba50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/3431180317.py:123: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self, h_size, state_space_n, state_vector_n, action_space_n):\n",
    "\n",
    "        self.state_space_n = state_space_n\n",
    "        self.action_space_n = action_space_n\n",
    "        self.state_vector_n = state_vector_n\n",
    "\n",
    "        # The network recieves a state number from\n",
    "        # It then resizes it and processes it through four convolutional layers.\n",
    "        self.vectorIn = tf.placeholder(shape=[None, state_vector_n], dtype=tf.float32)\n",
    "        #print(self.scalarInput)\n",
    "        #self.vectorIn = tf.one_hot(self.scalarInput, state_space_n, dtype=tf.float32)\n",
    "        #print(self.vectorIn)\n",
    "        self.fc1 = tf.layers.dense(self.vectorIn, h_size, activation=tf.nn.relu)\n",
    "        #print(self.fc1)\n",
    "        self.fc2 = tf.layers.dense(self.fc1, h_size, activation=tf.nn.relu)\n",
    "        #print(self.fc2)\n",
    "\n",
    "        '''\n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1, 84, 84, 3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn, num_outputs=32, kernel_size=[8, 8], stride=[4, 4], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1, num_outputs=64, kernel_size=[4, 4], stride=[2, 2], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2, num_outputs=64, kernel_size=[3, 3], stride=[1, 1], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3, num_outputs=h_size, kernel_size=[7, 7], stride=[1, 1], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        '''\n",
    "\n",
    "        # We take the output from the final layer and split it into separate advantage and value streams.\n",
    "        #self.streamAC, self.streamVC = tf.split(self.conv4, 2, 3)\n",
    "        #self.streamA = slim.flatten(self.streamAC)\n",
    "        #self.streamV = slim.flatten(self.streamVC)\n",
    "\n",
    "        #print(self.fc2)\n",
    "\n",
    "        self.streamA, self.streamV = tf.split(self.fc2, 2, 1)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size // 2, action_space_n]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size // 2, 1]))\n",
    "        self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "        self.Value = tf.matmul(self.streamV, self.VW)\n",
    "        # Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage, axis=1, keep_dims=True))\n",
    "        #print(self.Qout)\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "\n",
    "        # Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, action_space_n, dtype=tf.float32)\n",
    "\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "\n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "\n",
    "    def get_Q_table(self, sess, s):\n",
    "        Q = sess.run(self.Qout, feed_dict={self.vectorIn:[s]})\n",
    "        Q = np.reshape(Q, [-1])\n",
    "        return Q\n",
    "\n",
    "    def act_epsilon_greedy(self, sess, s, e = 0):\n",
    "\n",
    "        #legal_move_list = env.legal_move_list(s)\n",
    "        #legal_move_list = range(env._action_space_n)\n",
    "\n",
    "        if np.random.rand(1) < e:\n",
    "            a = np.random.choice(self.action_space_n)\n",
    "        else:\n",
    "            Q = self.get_Q_table(sess, s)\n",
    "            a = np.argmax(Q)\n",
    "\n",
    "            '''\n",
    "            #print(Q)\n",
    "            a = 0\n",
    "            val = -100000\n",
    "            for i in range(self.):\n",
    "                if (Q[i] > val):\n",
    "                    val = Q[i]\n",
    "                    a = i\n",
    "            '''\n",
    "\n",
    "        return a\n",
    "\n",
    "    def get_policy_table(self, sess, env):\n",
    "        policy = np.zeros(self.state_space_n, dtype = np.int32)\n",
    "        for i in range(0, self.state_space_n):\n",
    "            ss = env._index_to_vector(i)\n",
    "            policy[i] = self.act_epsilon_greedy(sess, ss, 0)\n",
    "        return policy\n",
    "\n",
    "HIDDEN_BLOCK = 20 # maximum hidden block of attacker\n",
    "rule = \"longest\" # \"longest\" -- bitcoin rule, \"GHOST\" -- GHOST rule\n",
    "h_size = 100 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "path = \"./btc_\" + rule + str(HIDDEN_BLOCK) + \"_\" + str(h_size) #The path to save our model to.\n",
    "know_alpha = True # if the agent knows the current alpha.\n",
    "# if know_alpha == True: path += \"know_alpha\"\n",
    "best_path = path + \"_cp/model_best.ckpt\" # best model path\n",
    "\n",
    "stale_rate = 0.0 # stale block rate, 0 means no stale block -- the classical selfish mining setting\n",
    "ALPHA = 0.4 # the hash power fraction of attacker\n",
    "GAMMA = 0.5 # the follower's fraction\n",
    "DEV = 0.0 # the alpha's fluctuation rate, 0 means fixed alpha\n",
    "know_alpha = True # if the agent knows the current alpha.\n",
    "random_process = \"iid\" # or \"brown\" -- brownian process\n",
    "interval = (0, 0.5) # the range of the alpha\n",
    "\n",
    "env = SM_env_with_stale(max_hidden_block = HIDDEN_BLOCK, attacker_fraction = ALPHA, follower_fraction = GAMMA, rule = rule, stale_rate=stale_rate, dev = DEV, know_alpha = know_alpha, random_interval=interval, random_process = random_process, frequency=6)\n",
    "\n",
    "h_size = 100 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "load_best_model = True # load a saved best model\n",
    "init = tf.global_variables_initializer()\n",
    "mainQN = Qnetwork(h_size, env._state_space_n, env._state_vector_n, env._action_space_n)\n",
    "targetQN = Qnetwork(h_size, env._state_space_n, env._state_vector_n, env._action_space_n)\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tra = 100\n",
    "seed_trial = 5\n",
    "index_file = 'episode_15/train_index.txt'\n",
    "index_pd = pd.read_table(index_file, sep=';', header=None)\n",
    "index_loc = index_pd[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/2326350900.py:1: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3364787/2326350900.py:1: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Loading Best Model..\n",
      "WARNING:tensorflow:From /home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    if load_best_model == True:\n",
    "        print('Loading Best Model..')\n",
    "        saver.restore(sess, best_path)\n",
    "\n",
    "    reward_origin = []\n",
    "    for index in range(num_tra):\n",
    "        env.seed(index_loc[index])\n",
    "        s = env.reset()\n",
    "        s_0 = s\n",
    "        r_total = 0\n",
    "        for i in range(100):\n",
    "            a = mainQN.act_epsilon_greedy(sess, s, 0)\n",
    "            s, r, d, _ = env.step(s, a, move = True)\n",
    "            r_total += r\n",
    "            if s == s_0:\n",
    "                break\n",
    "        reward_origin.append(r_total)\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def random_run(choice_state,reward_origin):\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        if load_best_model == True:\n",
    "            print('Loading Best Model..')\n",
    "            saver.restore(sess, best_path)\n",
    "\n",
    "        reward_random = []\n",
    "        for index in range(num_tra):\n",
    "            # print(index)\n",
    "            break_state = choice_state[index] - 1\n",
    "            # break_state = 180\n",
    "            flag = False\n",
    "            average = []\n",
    "            for t in range(seed_trial):\n",
    "                env.seed(index_loc[index])\n",
    "                s = env.reset()\n",
    "                s_0 = s\n",
    "                if flag:\n",
    "                    continue\n",
    "                r_total = 0\n",
    "                modifiable = False\n",
    "                for i in range(200):\n",
    "                    a = mainQN.act_epsilon_greedy(sess, s, 0)\n",
    "                    if (i==break_state):\n",
    "                        modifiable = True\n",
    "                        legal_state = env.legal_move_list(s)\n",
    "                        if a not in legal_state:\n",
    "                            a = legal_state[0]\n",
    "                        legal_state.remove(a)\n",
    "                        if len(legal_state)==0:\n",
    "                            flag = True\n",
    "                            break\n",
    "                        elif len(legal_state)==1:\n",
    "                            a = legal_state[0]\n",
    "                        elif len(legal_state)==2:\n",
    "                            a = choice(legal_state)\n",
    "                        # print(\"The action is: \", a)\n",
    "                    s, r, d, _ = env.step(s, a, move = True)\n",
    "                    r_total+=r\n",
    "                    # line = (\"The block index is \" + str(i) + \"         \"+ str(s[0]) + \";\" + str(s[1]) + \";\" + str(s[3]) + \";\")\n",
    "                    # print(line)\n",
    "                    if flag==False and s == s_0:\n",
    "                        break\n",
    "                    \n",
    "                    # if (i==break_state):\n",
    "                    #     env.seed(2021+index+100+t)\n",
    "                if flag==False and modifiable==True:\n",
    "                    average.append(abs(r_total-reward_origin[index]))\n",
    "\n",
    "            if len(average)==0:\n",
    "                r=-1\n",
    "            else:\n",
    "                r = sum(average) / len(average)\n",
    "                # r = max(average)\n",
    "            reward_random.append(r)\n",
    "        sess.close()\n",
    "    return reward_random\n",
    "\n",
    "def read_loc(method):\n",
    "    summary = 'summary_explain/' + method + '.txt'\n",
    "    summary_pd = pd.read_table(summary, sep=';', header=None)\n",
    "    return summary_pd[0].values\n",
    "\n",
    "def process(loc,num,reward_origin,thres=100):\n",
    "\n",
    "    dif = random_run(loc,reward_origin)\n",
    "    sum = 0\n",
    "    num = 0\n",
    "    for i in range(len(dif)):\n",
    "        if 0<=dif[i]<thres:\n",
    "            sum+=dif[i]\n",
    "            num+=1\n",
    "    return sum/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100_cp/model_best.ckpt\n",
      "1.6777600979192167 0.9497868217054263 1.4417955651703622 1.3581536293164196 1.2528922371437927 1.3197219994653835 0.9092343872484973\n"
     ]
    }
   ],
   "source": [
    "con_loc = read_loc('concept')\n",
    "att_loc = read_loc('attention')\n",
    "the_loc = read_loc('theta')\n",
    "sal_loc = read_loc('saliency')\n",
    "smo_loc = read_loc('smooth')\n",
    "int_loc = read_loc('integrated')\n",
    "ran_loc = np.random.randint(5,10,size=[num_tra])\n",
    "\n",
    "con_diff = process(con_loc,num_tra,reward_origin)\n",
    "att_diff = process(att_loc,num_tra,reward_origin)\n",
    "the_diff = process(the_loc,num_tra,reward_origin)\n",
    "sal_diff = process(sal_loc,num_tra,reward_origin)\n",
    "smo_diff = process(smo_loc,num_tra,reward_origin)\n",
    "int_diff = process(int_loc,num_tra,reward_origin)\n",
    "ran_diff = process(ran_loc,num_tra,reward_origin)\n",
    "\n",
    "\n",
    "print(con_diff,att_diff,the_diff,sal_diff,smo_diff,int_diff,ran_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e409cc3a94ad8bb9234f76c4cd8bbe147f9fb06eb07002607ea27bc862dccc92"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

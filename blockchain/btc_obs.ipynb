{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/111925030.py:18: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "from environment import SM_env\n",
    "from environment import random_normal_trunc\n",
    "from environment import eth_env\n",
    "from environment import SM_env_with_stale\n",
    "from environment import random_normal_trunc\n",
    "import mdptoolbox\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self, h_size, state_space_n, state_vector_n, action_space_n):\n",
    "\n",
    "        self.state_space_n = state_space_n\n",
    "        self.action_space_n = action_space_n\n",
    "        self.state_vector_n = state_vector_n\n",
    "\n",
    "        # The network recieves a state number from\n",
    "        # It then resizes it and processes it through four convolutional layers.\n",
    "        self.vectorIn = tf.placeholder(shape=[None, state_vector_n], dtype=tf.float32)\n",
    "        #print(self.scalarInput)\n",
    "        #self.vectorIn = tf.one_hot(self.scalarInput, state_space_n, dtype=tf.float32)\n",
    "        #print(self.vectorIn)\n",
    "        self.fc1 = tf.layers.dense(self.vectorIn, h_size, activation=tf.nn.relu)\n",
    "        #print(self.fc1)\n",
    "        self.fc2 = tf.layers.dense(self.fc1, h_size, activation=tf.nn.relu)\n",
    "        #print(self.fc2)\n",
    "\n",
    "        '''\n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1, 84, 84, 3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn, num_outputs=32, kernel_size=[8, 8], stride=[4, 4], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1, num_outputs=64, kernel_size=[4, 4], stride=[2, 2], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2, num_outputs=64, kernel_size=[3, 3], stride=[1, 1], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3, num_outputs=h_size, kernel_size=[7, 7], stride=[1, 1], padding='VALID',\n",
    "            biases_initializer=None)\n",
    "        '''\n",
    "\n",
    "        # We take the output from the final layer and split it into separate advantage and value streams.\n",
    "        #self.streamAC, self.streamVC = tf.split(self.conv4, 2, 3)\n",
    "        #self.streamA = slim.flatten(self.streamAC)\n",
    "        #self.streamV = slim.flatten(self.streamVC)\n",
    "\n",
    "        #print(self.fc2)\n",
    "\n",
    "        self.streamA, self.streamV = tf.split(self.fc2, 2, 1)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size // 2, action_space_n]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size // 2, 1]))\n",
    "        self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "        self.Value = tf.matmul(self.streamV, self.VW)\n",
    "        # Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage, axis=1, keep_dims=True))\n",
    "        #print(self.Qout)\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "\n",
    "        # Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, action_space_n, dtype=tf.float32)\n",
    "\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "\n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "\n",
    "    def get_Q_table(self, sess, s):\n",
    "        Q = sess.run(self.Qout, feed_dict={self.vectorIn:[s]})\n",
    "        Q = np.reshape(Q, [-1])\n",
    "        return Q\n",
    "\n",
    "    def act_epsilon_greedy(self, sess, s, e = 0):\n",
    "\n",
    "        #legal_move_list = env.legal_move_list(s)\n",
    "        #legal_move_list = range(env._action_space_n)\n",
    "\n",
    "        if np.random.rand(1) < e:\n",
    "            a = np.random.choice(self.action_space_n)\n",
    "        else:\n",
    "            Q = self.get_Q_table(sess, s)\n",
    "            a = np.argmax(Q)\n",
    "\n",
    "            '''\n",
    "            #print(Q)\n",
    "            a = 0\n",
    "            val = -100000\n",
    "            for i in range(self.):\n",
    "                if (Q[i] > val):\n",
    "                    val = Q[i]\n",
    "                    a = i\n",
    "            '''\n",
    "\n",
    "        return a\n",
    "\n",
    "    def get_policy_table(self, sess, env):\n",
    "        policy = np.zeros(self.state_space_n, dtype = np.int32)\n",
    "        for i in range(0, self.state_space_n):\n",
    "            ss = env._index_to_vector(i)\n",
    "            policy[i] = self.act_epsilon_greedy(sess, ss, 0)\n",
    "        return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_BLOCK = 20 # maximum hidden block of attacker\n",
    "rule = \"longest\" # \"longest\" -- bitcoin rule, \"GHOST\" -- GHOST rule\n",
    "h_size = 100 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "path = \"./btc_\" + rule + str(HIDDEN_BLOCK) + \"_\" + str(h_size) #The path to save our model to.\n",
    "know_alpha = True # if the agent knows the current alpha.\n",
    "# if know_alpha == True: path += \"know_alpha\"\n",
    "best_path = path + \"/model_best.ckpt\" # best model path\n",
    "\n",
    "stale_rate = 0.0 # stale block rate, 0 means no stale block -- the classical selfish mining setting\n",
    "ALPHA = 0.4 # the hash power fraction of attacker\n",
    "GAMMA = 0.5 # the follower's fraction\n",
    "DEV = 0.0 # the alpha's fluctuation rate, 0 means fixed alpha\n",
    "know_alpha = True # if the agent knows the current alpha.\n",
    "random_process = \"iid\" # or \"brown\" -- brownian process\n",
    "interval = (0, 0.5) # the range of the alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space size =  733\n"
     ]
    }
   ],
   "source": [
    "env = SM_env_with_stale(max_hidden_block = HIDDEN_BLOCK, attacker_fraction = ALPHA, follower_fraction = GAMMA, rule = rule, stale_rate=stale_rate, dev = DEV, know_alpha = know_alpha, random_interval=interval, random_process = random_process, frequency=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/3485013516.py:3: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/2538090048.py:10: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/2538090048.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/jvy5516/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2858534690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2858534690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2858534690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2858534690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f285857fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f285857fd90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f285857fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f285857fd90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/2538090048.py:62: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f27d32e80d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1313217/3485013516.py:6: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_size = 100 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "load_best_model = True # load a saved best model\n",
    "init = tf.global_variables_initializer()\n",
    "mainQN = Qnetwork(h_size, env._state_space_n, env._state_vector_n, env._action_space_n)\n",
    "targetQN = Qnetwork(h_size, env._state_space_n, env._state_vector_n, env._action_space_n)\n",
    "saver = tf.train.Saver()\n",
    "rept=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Best Model..\n",
      "INFO:tensorflow:Restoring parameters from ./btc_longest20_100/model_best.ckpt\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "rept=10000000000000\n",
    "num = 10000\n",
    "log_file_path = './episode_15/train/'\n",
    "index_file = './episode_15/train_index.txt'\n",
    "padding_file = './episode_15/padding_index.txt'\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    if load_best_model == True:\n",
    "        print('Loading Best Model..')\n",
    "        saver.restore(sess, best_path)\n",
    "    cnt = 0\n",
    "    index_writter = open(index_file, \"w\")\n",
    "    padding_writter = open(padding_file, \"w\")\n",
    "    for index in range(rept):\n",
    "        if cnt==num:\n",
    "            break\n",
    "        env.seed(index)\n",
    "        s = env.reset()\n",
    "        s_0 = s\n",
    "        r_total = 0\n",
    "        to_write = \"\"\n",
    "        for i in range(100):\n",
    "            to_write += str(s[0]) + \";\" + str(s[1]) + \";\" + str(s[3]) + \";\" \n",
    "            if i!=0 and s==s_0:\n",
    "                if 10<=i<=14:\n",
    "                    file = open(log_file_path + str(index) + \".txt\", \"w\")\n",
    "                    to_write += str(0) + '\\n' + padding * (14-i) \n",
    "                    # to_write = padding * (14-i) + to_write + str(0) + '\\n'\n",
    "                    file.write(to_write)\n",
    "                    file.write(str(r_total) + \";\" + str(r_total) + \";\" + str(r_total) + \";\" + str(r_total))  #placeholder\n",
    "                    file.close()\n",
    "                    index_writter.write(str(index) + '\\n')\n",
    "                    padding_writter.write(str(14-i) + '\\n')\n",
    "                    cnt+=1\n",
    "                    print(cnt)\n",
    "                    break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            a = mainQN.act_epsilon_greedy(sess, s, 0)\n",
    "            s, r, d, _ = env.step(s, a, move = True)\n",
    "            to_write += str(r) + '\\n'\n",
    "            if i==0:\n",
    "                padding = to_write\n",
    "            r_total+=r\n",
    "    index_writter.close()\n",
    "    padding_writter.close()\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e409cc3a94ad8bb9234f76c4cd8bbe147f9fb06eb07002607ea27bc862dccc92"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
